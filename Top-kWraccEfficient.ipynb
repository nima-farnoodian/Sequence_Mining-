{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import time\n",
    "\n",
    "class Dataset_Sequence:\n",
    "    \"\"\"Utility class to manage a dataset stored in a external file.\"\"\"\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"reads the dataset file and initializes files\"\"\"\n",
    "        \"\"\"This class reads the file for sequence mining. Each line is an item \n",
    "        with its location and the transactions are separated by '\\n'\"\"\"\n",
    "        self.transactions = list()\n",
    "        self.items = set()\n",
    "        self.Freq_Items={}\n",
    "        #self.minSup=minSup\n",
    "        self.Vertical_Rep={}\n",
    "        try:\n",
    "            f=open(filepath,'r')\n",
    "            line=[]\n",
    "            idx=0\n",
    "            Freq_Items={}\n",
    "            for itemLoc in f.readlines():\n",
    "                if itemLoc!='\\n':\n",
    "                    itemLoc=itemLoc.strip()\n",
    "                    item=itemLoc.split(' ')[0]\n",
    "                    loc=int(itemLoc.split(' ')[1])\n",
    "                    line.append(item)\n",
    "                    if tuple([item]) not in self.Vertical_Rep:\n",
    "                        self.Vertical_Rep[tuple([item])]={}\n",
    "                    if idx not in self.Vertical_Rep[tuple([item])]:\n",
    "                        self.Vertical_Rep[tuple([item])][idx]=[]\n",
    "                    \n",
    "                    self.Vertical_Rep[tuple([item])][idx].append(loc)\n",
    "                    #self.Vertical_Rep[frozenset([item])].append((idx,loc))\n",
    "                    if item not in self.Freq_Items:\n",
    "                        self.Freq_Items[item]=1\n",
    "                        self.items.add(frozenset([item]))\n",
    "                    else:\n",
    "                        self.Freq_Items[item]+=1\n",
    "                else:\n",
    "                    idx+=1\n",
    "                    if idx>1:\n",
    "                        self.transactions.append(line)\n",
    "                    line=[]\n",
    "            #self.transactions.append(line)\n",
    "        except IOError as e:\n",
    "            print(\"Unable to read dataset file!\\n\" + e)\n",
    "\n",
    "    def trans_num(self):\n",
    "        \"\"\"Returns the number of transactions in the dataset\"\"\"\n",
    "        return len(self.transactions)\n",
    "\n",
    "    def items_num(self):\n",
    "        \"\"\"Returns the number of different items in the dataset\"\"\"\n",
    "        return len(self.items)\n",
    "\n",
    "    def get_transaction(self, i):\n",
    "        \"\"\"Returns the transaction at index i as an int array\"\"\"\n",
    "        return self.transactions[i]\n",
    "    def get_items(self):\n",
    "        return self.items\n",
    "    def get_freq_items(self,minSup):\n",
    "        TrNo=len(self.transactions)\n",
    "        AboveFreq=[i for i in self.Freq_Items if (self.Freq_Items[i]/TrNo)>=minSup]\n",
    "        return AboveFreq\n",
    "    \n",
    "    def get_freq_Vertical_Rep(self,minSup):\n",
    "        #  it returns the vertical representation of the frequent items\n",
    "        if minSup!=None:\n",
    "            TrNo=self.items_num()\n",
    "            High_freq=self.get_freq_items(minSup)\n",
    "            Vertical_Rep_high={}\n",
    "            for it in High_freq:\n",
    "                Vertical_Rep_high[tuple([it])]=self.Vertical_Rep[tuple([it])]\n",
    "        return Vertical_Rep_high\n",
    "    def get_items_in_order(self):\n",
    "        sequences=[i for i in sorted(self.Freq_Items.items(), key=lambda item: item[1],reverse=True)]\n",
    "        return sequences\n",
    "    \n",
    "class k_selector:\n",
    "    \"\"\"Utility class to control k-top elements.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, k,mode):\n",
    "        self.mode=mode # mode could be 'frequent' or 'infrequent'. if it is frequent, it holds top k frequent sequences, otherwise, infrequent \n",
    "        self.score_list = list() # a list of top k (or less than k) scores that have been observed so far\n",
    "        self.score_link = dict() # a dictionary where keys are the scores and the values are the sequences whose scores are equale to the key\n",
    "        self.k=k # the number of unique scores\n",
    "    def append(self,score,sequence):\n",
    "    \n",
    "        '''\n",
    "        Input: \n",
    "            score e.g, total support or Wracc\n",
    "            obtained sequence\n",
    "        Output:\n",
    "            return True if the sequence could be added to the top-k list sequences\n",
    "        '''\n",
    "        ret=False\n",
    "        if score not in self.score_link:\n",
    "            if len(self.score_list)<self.k:\n",
    "                self.score_list.append(score)\n",
    "                self.score_link[score]=set()\n",
    "                self.score_link[score].add(sequence)\n",
    "                ret=True\n",
    "            else:\n",
    "                if self.mode=='frequent':\n",
    "                    minimum=np.min(self.score_list)\n",
    "                    if score>minimum:\n",
    "                        self.score_list.pop(self.score_list.index(minimum))\n",
    "                        del(self.score_link[minimum])\n",
    "                        self.score_link[score]=set()\n",
    "                        self.score_list.append(score)\n",
    "                        self.score_link[score].add(sequence)\n",
    "                        ret=True\n",
    "                    if score==minimum:\n",
    "                        self.score_link[score].add(sequence)\n",
    "                        ret=True\n",
    "                elif self.mode=='infrequent':\n",
    "                    maximum=np.max(self.score_list)\n",
    "                    if score<maximum:\n",
    "                        self.score_list.pop(self.score_list.index(maximum))\n",
    "                        del(self.score_link[maximum])\n",
    "                        self.score_link[score]=set()\n",
    "                        self.score_list.append(score)\n",
    "                        self.score_link[score].add(sequence)\n",
    "                        ret=True\n",
    "                    if score==maximum:\n",
    "                        self.score_link[score].add(sequence)\n",
    "                        ret=True\n",
    "        else:\n",
    "            self.score_link[score].add(sequence)\n",
    "            ret=True\n",
    "        return ret\n",
    "    \n",
    "def vertical_finding(vr,left_vr,right_item):\n",
    "    \"\"\"This function is used to find the sequence using vertical representation (Sparse Lattice suggested in Zaki's paper)\"\"\"\n",
    "\n",
    "    '''\n",
    "    Input: \n",
    "        vertical representation provided by Dataset_Sequence class\n",
    "        left: vertical representation of the prefix e.g, AB\n",
    "        right_item= the candidate item added to the prefix e.g, C\n",
    "\n",
    "    Output:\n",
    "        res= vertical representation of the prefix + right_item  e.g, ABC\n",
    "        support= the support of the found sequence\n",
    "    '''\n",
    "    right_item=tuple(right_item)\n",
    "    right=vr.get(right_item,dict())\n",
    "    res={}\n",
    "    support=0\n",
    "    for x in left_vr:\n",
    "        if x in right:\n",
    "            break_Flage=False\n",
    "            for loc_left in left_vr[x]:\n",
    "                if break_Flage==False:\n",
    "                    for loc_right in right[x]:\n",
    "                        if loc_left<loc_right:\n",
    "                            if x not in res:\n",
    "                                res[x]=[]\n",
    "                            res[x].append(loc_right)\n",
    "                            support+=1\n",
    "                            break_Flage=True\n",
    "                            break\n",
    "                else:\n",
    "                    break\n",
    "    return res,support\n",
    "\n",
    "\n",
    "def topk_spade(data, k,printing=True,mode='frequent',top_frequent=None):\n",
    "    \"\"\" \n",
    "    Notice that this top-k spade is a bit different from the one submitted for task1. \n",
    "    mode could be 'frequent' or 'infrequent'. if it is frequent, it find top k frequent sequences, otherwise, infrequent \n",
    "    Top k SPADE Algorithm- Recursive DFS implementation\n",
    "    k is the number of top sequences that should be seleceted.\n",
    "    Notice that, both positive and negative supports for sequences are found in the same call using vertical finding function, thereby speeding up the algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    Input: \n",
    "        data_positive= positive class data provided by Dataset_Sequence class\n",
    "        data_negative= negative class data provided by Dataset_Sequence class\n",
    "        k: k is the number of top sequences that should be seleceted.\n",
    "        printing= if True, print the top k frequent sequences (e.g, [A, B, C] supp_positive supp_negative score)\n",
    "\n",
    "    Output:\n",
    "        None \n",
    "    '''\n",
    "    if k==0:\n",
    "        print('k==0 is not feasible')\n",
    "        return None\n",
    "    \n",
    "    if mode=='infrequent':\n",
    "        if top_frequent!=None:\n",
    "            if type(top_frequent)!=dict:\n",
    "                print('Top_frequent must be a dictionary whose keys are frequent sequences and valuse are the supports')\n",
    "                return None\n",
    "        else:\n",
    "            print('Top_frequent must be a dictionary whose keys are frequent sequences and valuse are the supports')\n",
    "            return None\n",
    "    selector=k_selector(k,mode)\n",
    "    vr=data.get_freq_Vertical_Rep(0) \n",
    "    #vr_negative=data_negative.get_freq_Vertical_Rep(0) \n",
    "    \n",
    "    total_trans = data.trans_num() \n",
    "    #total_trans_negative = data_negative.trans_num() \n",
    "    #total_trans=total_trans_positive+total_trans_negative\n",
    "    SequenceSet={}\n",
    "    #items=list(set(data_positive.get_freq_items(0)).union(set(data_negative.get_freq_items(0)))) # find all items observed in positive and negative classes\n",
    "    items=data.get_freq_items(0)\n",
    "    ordered_item={}\n",
    "    # the following block select only top k single items. It is used to prune the search as top k problem benefits from Anti-monotonicity \n",
    "    if mode=='frequent':\n",
    "        for item in items:\n",
    "            supp=(len(vr.get(tuple([item]),[])))\n",
    "            #supp_negative=(len(vr_negative.get(tuple([item]),[])))\n",
    "            selector.append(supp,tuple([item]))\n",
    "        selected_item=[]\n",
    "        scores=sorted(selector.score_link.keys(),reverse=True)\n",
    "        scores=sorted(selector.score_link.keys(),reverse=False)\n",
    "        for score in scores:\n",
    "                for sequence in selector.score_link[score]:\n",
    "                    selected_item.append(sequence)\n",
    "        selected_item=[i[0] for i in selected_item]\n",
    "    elif mode=='infrequent':\n",
    "        selected_item=items\n",
    "    # end of block \n",
    "    for item in selected_item:\n",
    "        supp=(len(vr.get(tuple([item]),[])))\n",
    "        #supp_negative=(len(vr_negative.get(tuple([item]),[])))\n",
    "        if mode=='frequent':\n",
    "            if supp>0:\n",
    "                SequenceSet[tuple([item])]=[supp]\n",
    "                project_vr=vr.get(tuple([item]),dict())\n",
    "                topk_depthFirstSearch(item, total_trans,vr,SequenceSet,selected_item,project_vr,selector,mode)\n",
    "        elif mode=='infrequent':\n",
    "            if supp>0:\n",
    "                SequenceSet[tuple([item])]=[supp]\n",
    "                project_vr=vr.get(tuple([item]),dict())\n",
    "                topk_depthFirstSearch(item, total_trans,vr,SequenceSet,selected_item,project_vr,selector,mode,top_frequent)\n",
    "            continue\n",
    "\n",
    "    counter=0\n",
    "    scores=sorted(selector.score_link.keys(),reverse=True)\n",
    "    top_k_list={}\n",
    "    for score in scores:\n",
    "        for sequence in selector.score_link[score]:\n",
    "            top_k_list[sequence]=SequenceSet[sequence][0]\n",
    "            if printing==True:\n",
    "                out='['+', '.join(list(sequence))+']' \n",
    "                print(out,SequenceSet[sequence][0])\n",
    "            counter+=1\n",
    "            #print(counter)\n",
    "    return top_k_list\n",
    "\n",
    "def topk_depthFirstSearch(item, total_trans,vr,SequenceSet,exploredLocal,projected_vr,selector,mode,top_frequent=None):\n",
    "    if type(item)!=list:\n",
    "        item=[item]\n",
    "    for item2 in exploredLocal:\n",
    "        item2=[item2]\n",
    "        if mode=='frequent':\n",
    "            res,supp=vertical_finding(vr,projected_vr,item2)\n",
    "            #res_negative,supp_negative=vertical_finding(vr_negative,projected_vr_negative,item2)\n",
    "            if(supp/total_trans > 0.0):\n",
    "                sequence=item+item2\n",
    "                selected=selector.append(supp,tuple(sequence))\n",
    "                if selected: # if the sequence was added to the top k list, so it is frequent and its supersequences may be top-k frequent sequences as well\n",
    "                    if tuple(sequence) not in SequenceSet:\n",
    "                        SequenceSet[tuple(sequence)]=[supp]\n",
    "                        topk_depthFirstSearch(sequence, total_trans,vr,SequenceSet,exploredLocal,res,selector,mode,top_frequent) # discover supersequences\n",
    "        elif mode=='infrequent':\n",
    "            sequence=item+item2\n",
    "            if tuple(sequence) in top_frequent:\n",
    "                res,supp=vertical_finding(vr,projected_vr,item2)\n",
    "                selected=selector.append(supp,tuple(sequence))\n",
    "                if selected: # if the sequence was added to the top k list, so it is frequent and its supersequences may be top-k frequent sequences as well\n",
    "                    if tuple(sequence) not in SequenceSet:\n",
    "                        SequenceSet[tuple(sequence)]=[supp]\n",
    "                        topk_depthFirstSearch(sequence, total_trans,vr,SequenceSet,exploredLocal,res,selector,mode,top_frequent) # discover supersequences\n",
    "            \n",
    "    return SequenceSet\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C, A] 4\n",
      "[A, C] 4\n",
      "[C] 4\n",
      "[A, A] 4\n",
      "[A] 4\n",
      "[A, C, A] 4\n",
      "[A, A, A] 3\n",
      "[C, C, A] 3\n",
      "[A, C, C, A] 3\n",
      "[A, B] 3\n",
      "[A, A, C] 3\n",
      "[A, B, A] 3\n",
      "[B] 3\n",
      "[A, C, C] 3\n",
      "[A, A, C, A] 3\n",
      "[B, A] 3\n",
      "[C, C] 3\n"
     ]
    }
   ],
   "source": [
    "pos_filepath = 'positive.txt'# filepath to positive class file\n",
    "neg_filepath = 'negative.txt' # filepath to negative class file\n",
    "k = 2\n",
    "# TODO: read the dataset files and call your miner to print the top k itemsets\n",
    "ds_positive=Dataset_Sequence(pos_filepath)\n",
    "ds_negative=Dataset_Sequence(neg_filepath)\n",
    "\n",
    "selected_pos=topk_spade(ds_positive,k,printing=True,mode='frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A, C] 1\n",
      "[A, C, C, A] 1\n",
      "[A, B, A] 1\n",
      "[A, C, C] 1\n",
      "[A, C, A] 1\n",
      "[A, A, A] 0\n",
      "[A, A, C, A] 0\n",
      "[A, A, C] 0\n"
     ]
    }
   ],
   "source": [
    "pos_filepath = 'positive.txt'# filepath to positive class file\n",
    "neg_filepath = 'negative.txt' # filepath to negative class file\n",
    "k = 2\n",
    "# TODO: read the dataset files and call your miner to print the top k itemsets\n",
    "ds_positive=Dataset_Sequence(pos_filepath)\n",
    "ds_negative=Dataset_Sequence(neg_filepath)\n",
    "\n",
    "selected_neg=topk_spade(ds_negative,k,printing=True,mode='infrequent',top_frequent=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'A'): 2,\n",
       " ('C', 'C'): 2,\n",
       " ('A', 'B'): 2,\n",
       " ('C', 'C', 'A'): 2,\n",
       " ('A', 'C'): 1,\n",
       " ('A', 'C', 'C', 'A'): 1,\n",
       " ('A', 'B', 'A'): 1,\n",
       " ('A', 'C', 'C'): 1,\n",
       " ('A', 'C', 'A'): 1,\n",
       " ('A', 'A', 'A'): 0,\n",
       " ('A', 'A', 'C', 'A'): 0,\n",
       " ('A', 'A', 'C'): 0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pos_filepath = 'positive.txt' # filepath to positive class file\n",
    "    neg_filepath = 'negative.txt' # filepath to negative class file\n",
    "    k = 6\n",
    "    # TODO: read the dataset files and call your miner to print the top k itemsets\n",
    "    ds_positive=Dataset_Sequence(pos_filepath)\n",
    "    P=ds_positive.trans_num() #  The number of transactions in positive class\n",
    "    ds_negative=Dataset_Sequence(neg_filepath)\n",
    "    N=ds_negative.trans_num() #  The number of transactions in negative class\n",
    "    total=P+N\n",
    "\n",
    "    positive_seqs=topk_spade(ds_positive, 6,printing=False,mode='frequent')\n",
    "    negative_seqs=topk_spade(ds_negative, 6,printing=False,mode='infrequent',top_frequent=positive_seqs)\n",
    "\n",
    "    wracc_left=(P/total)*(N/total)\n",
    "    \n",
    "    Positive_seq_Discoverd=set(positive_seqs.keys())\n",
    "    Negative_seq_Discoverd=set(negative_seqs.keys())\n",
    "    To_discovere=Positive_seq_Discoverd.intersection(Negative_seq_Discoverd)\n",
    "    \n",
    "    # the following wracc_x is added to compute weighted relative accuracy (Wracc)\n",
    "    sequences={}\n",
    "    for sequence in To_discovere:\n",
    "        wracc_x=wracc_left*((positive_seqs.get(sequence,0)/P)-(negative_seqs.get(sequence,0)/N))\n",
    "        #sequences[sequence]=[positive_seqs.get(sequence,0),negative_seqs.get(sequence,0),np.round(wracc_x,5)]\n",
    "        sequences[sequence]=[positive_seqs.get(sequence,0),negative_seqs.get(sequence,0),np.round(wracc_x,5)]\n",
    "\n",
    "    sequences=sorted(sequences.items(), key=lambda item: item[1][2],reverse=True)\n",
    "    i=1\n",
    "    j=0\n",
    "    prev=sequences[0][1][2]\n",
    "    for sequence in sequences:\n",
    "        if sequence[1][2]!=prev:\n",
    "            i+=1\n",
    "            prev=sequence[1][2]\n",
    "        if i<=k:\n",
    "            out='['+', '.join(list(sequence[0]))+']'\n",
    "            print(out,sequence[1][0],sequence[1][1],sequence[1][2])\n",
    "            j+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A, A, A] 3 0 0.18367\n",
      "[A, A, C] 3 0 0.18367\n",
      "[A, A, C, A] 3 0 0.18367\n",
      "[A, C, A] 4 1 0.16327\n",
      "[A, C] 4 1 0.16327\n",
      "[A, C, C, A] 3 1 0.10204\n",
      "[A, B, A] 3 1 0.10204\n",
      "[A, C, C] 3 1 0.10204\n",
      "[A, A] 4 2 0.08163\n",
      "[B, C, C, A] 1 0 0.06122\n",
      "[A, C, C, B, A] 1 0 0.06122\n",
      "[A, C, A, A] 1 0 0.06122\n",
      "[A, B, B, A, C, A] 1 0 0.06122\n",
      "[A, C, A, C, A] 1 0 0.06122\n",
      "[B, A, C, A] 1 0 0.06122\n",
      "[A, B, C, C, A] 1 0 0.06122\n",
      "[A, B, B, A, C] 1 0 0.06122\n",
      "[A, B, A, C] 1 0 0.06122\n",
      "[A, A, C, C] 1 0 0.06122\n",
      "[A, B, B, C, A] 1 0 0.06122\n",
      "[C, C, C] 1 0 0.06122\n",
      "[A, C, C, A, A] 1 0 0.06122\n",
      "[B, C, C] 1 0 0.06122\n",
      "[A, C, A, C] 1 0 0.06122\n",
      "[A, A, B, A] 1 0 0.06122\n",
      "[A, B, B, C] 1 0 0.06122\n",
      "[A, A, B, C, C, A] 1 0 0.06122\n",
      "[C, A, C, A] 1 0 0.06122\n",
      "[B, B, A, C, A] 1 0 0.06122\n",
      "[B, B, A, C] 1 0 0.06122\n",
      "[A, A, B, C, A] 1 0 0.06122\n",
      "[A, C, C, A, C, A] 1 0 0.06122\n",
      "[A, C, C, A, C] 1 0 0.06122\n",
      "[C, C, A, C, A] 1 0 0.06122\n",
      "[A, B, C, C] 1 0 0.06122\n",
      "[A, C, C, B, B] 1 0 0.06122\n",
      "[A, C, C, B, A, B] 1 0 0.06122\n",
      "[A, B, A, C, A] 1 0 0.06122\n",
      "[A, C, C, C, A] 1 0 0.06122\n",
      "[A, A, B, C] 1 0 0.06122\n",
      "[C, A, C] 1 0 0.06122\n",
      "[C, C, A, C] 1 0 0.06122\n",
      "[B, B, C] 1 0 0.06122\n",
      "[A, B, B, A] 1 0 0.06122\n",
      "[A, B, B, A, A] 1 0 0.06122\n",
      "[B, A, C] 1 0 0.06122\n",
      "[A, B, A, A] 1 0 0.06122\n",
      "[A, C, C, C] 1 0 0.06122\n",
      "[A, A, C, C, A] 1 0 0.06122\n",
      "[C, C, C, A] 1 0 0.06122\n",
      "[C, C, B, A, B] 1 0 0.06122\n",
      "[B, B, C, A] 1 0 0.06122\n",
      "[A, A, B, C, C] 1 0 0.06122\n",
      "[A, B, C] 2 1 0.04082\n",
      "[A, B, C, A] 2 1 0.04082\n",
      "[A, A, B] 2 1 0.04082\n",
      "[B, C, A] 2 1 0.04082\n",
      "[B, C] 2 1 0.04082\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
